{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93d4afc0cc5d21fd",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Import Librarires And Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c3980ae6c078aa64",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:32.310721Z",
     "start_time": "2024-04-02T07:39:32.304604Z"
    }
   },
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "#some settings to show data\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "#import dataset\n",
    "audit_risk = pd.read_csv(\"datasets/audit_risk.csv\")\n",
    "trial = pd.read_csv(\"datasets/trial.csv\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a4bb796ede4ad52a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Show Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "91d85799c25bbbf9",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:33.052460Z",
     "start_time": "2024-04-02T07:39:33.036732Z"
    }
   },
   "source": [
    "audit_risk.head(10)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a9182022dbeca44f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:33.079356Z",
     "start_time": "2024-04-02T07:39:33.071048Z"
    }
   },
   "source": [
    "trial.head(10)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a66b5d44b7351844",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Lets See Values Of Two Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a73aeaacff2883a6",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:33.141017Z",
     "start_time": "2024-04-02T07:39:33.114358Z"
    }
   },
   "source": [
    "audit_risk.describe()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "40615ed3b458df04",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:33.179070Z",
     "start_time": "2024-04-02T07:39:33.162032Z"
    }
   },
   "source": [
    "trial.describe()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "647fe5f5ef79d0f0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Analysis**\n",
    "\n",
    "As you can see, two dataset are similarly same expect a bit difference. \n",
    "Firsty, SCORE_A AND SCORE_B in trial, multiply 10 with audit_risk Score_A and Score_B values, also that's capital. \n",
    "Second, Loss and Risk column in trial, completely different from audit_risk.\n",
    "\n",
    "First of all, change capital column names like audit_risk columns, then divide by 10 to Score_A and Score_B;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ea1c187784d5b33d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:33.268948Z",
     "start_time": "2024-04-02T07:39:33.266876Z"
    }
   },
   "source": [
    "trial.columns = ['Sector_score', 'LOCATION_ID', 'PARA_A', 'Score_A', 'PARA_B',\n",
    "                 'Score_B', 'TOTAL', 'numbers', 'Marks',\n",
    "                 'Money_Value', 'MONEY_Marks', 'District',\n",
    "                 'Loss', 'LOSS_SCORE', 'History', 'History_score', 'Score', 'Risk_trial']"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "98a65e9495d4e3ca",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:33.332500Z",
     "start_time": "2024-04-02T07:39:33.330010Z"
    }
   },
   "source": [
    "trial['Score_A'] = trial['Score_A'] / 10\n",
    "trial['Score_B'] = trial['Score_B'] / 10"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "75b36c0b2d8f929b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Observe two dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cc9a73a12324aa74",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:33.423719Z",
     "start_time": "2024-04-02T07:39:33.421095Z"
    }
   },
   "source": [
    "same_columns = np.intersect1d(audit_risk.columns, trial.columns)\n",
    "same_columns"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "5fb3034f267dc364",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Let's merge two dataset with same column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4031d1cf103bf025",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:33.499263Z",
     "start_time": "2024-04-02T07:39:33.493955Z"
    }
   },
   "source": [
    "merged_df = pd.merge(audit_risk, trial, how='outer',\n",
    "                     on=['History', 'LOCATION_ID', 'Money_Value', 'PARA_A', 'PARA_B', 'Score', 'Score_A', 'Score_B',\n",
    "                         'Sector_score', 'TOTAL', 'numbers'])\n",
    "merged_df.columns"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "55df7ce7fb8adccf",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Analysis**\n",
    "\n",
    "As you can see some values in Risk_trial in trial and Risk in audit_risk are different, we can select Risk column in audit_risk because if you will click link https://api.openml.org/d/42931, you can see target value is Risk in audit_risk dataset. So delete that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a49b37371871b6a6",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:33.620695Z",
     "start_time": "2024-04-02T07:39:33.618314Z"
    }
   },
   "source": [
    "df = merged_df.drop(['Risk_trial'], axis=1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "bd5bcc8444f2955a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Check null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "65be6230dcfbb06f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:33.659544Z",
     "start_time": "2024-04-02T07:39:33.656201Z"
    }
   },
   "source": [
    "df.isnull().sum()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "90fd5295d73d4eaf",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "As you can see, Money_Value column has a null value. Set average value,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ea0238ae1b1e1ba7",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:33.739113Z",
     "start_time": "2024-04-02T07:39:33.736775Z"
    }
   },
   "source": [
    "df['Money_Value'] = df['Money_Value'].fillna(df['Money_Value'].median())"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "2c5e43d2ebaad018",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "and Detection_Risk column is same value of Risk column, so delete it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d667112a038772cd",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:33.758214Z",
     "start_time": "2024-04-02T07:39:33.752826Z"
    }
   },
   "source": [
    "df = df.drop(['Detection_Risk'], axis=1)\n",
    "df.info()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "e711c4773c62d91b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Up to now, everything is good, let's see location id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "afb18b60505b06c3",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:33.780607Z",
     "start_time": "2024-04-02T07:39:33.778037Z"
    }
   },
   "source": [
    "df[\"LOCATION_ID\"].unique()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "d3cd2dc5773a86b0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "if you iterate to showed values, you will see end of the table there are some non numeric values, LOHARU, NUH and SAFIDON. How much that values in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1440609eb3c3407e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:33.840407Z",
     "start_time": "2024-04-02T07:39:33.837244Z"
    }
   },
   "source": [
    "len(df[(df[\"LOCATION_ID\"] == 'LOHARU') | (df[\"LOCATION_ID\"] == 'NUH') | (df[\"LOCATION_ID\"] == 'SAFIDON')])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "86b1dcf5db5c4829",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:33.872601Z",
     "start_time": "2024-04-02T07:39:33.870232Z"
    }
   },
   "source": [
    "len(df)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "5204ca86ad943dbc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Only 3 rows we have non numerical rows, so they seem deletable, i deleted it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "92e7e1fd3329f41b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:33.954472Z",
     "start_time": "2024-04-02T07:39:33.950877Z"
    }
   },
   "source": [
    "df = df[(df.LOCATION_ID != 'LOHARU')]\n",
    "df = df[(df.LOCATION_ID != 'NUH')]\n",
    "df = df[(df.LOCATION_ID != 'SAFIDON')]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "12710a869bbc1361",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:33.992753Z",
     "start_time": "2024-04-02T07:39:33.990472Z"
    }
   },
   "source": [
    "len(df)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "956ef4fd06508190",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Also i drop duplicate values,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "eb3eb29e96bf7ce5",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:34.070471Z",
     "start_time": "2024-04-02T07:39:34.065860Z"
    }
   },
   "source": [
    "df = df.drop_duplicates(keep='first')\n",
    "print(f\"Rows: {len(df)}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "3d1bdc6a040a4785",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "i drop high correlation values;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f20d7b9e3d5467fa",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:34.123961Z",
     "start_time": "2024-04-02T07:39:34.096335Z"
    }
   },
   "source": [
    "import seaborn as sns\n",
    "\n",
    "corr = df.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')\n",
    "# 'RdBu_r' & 'BrBG' are other good diverging colormaps\n",
    "cm = sns.diverging_palette(220, 20, sep=20, as_cmap=True)\n",
    "corr.style.background_gradient(cmap=cm)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "23e45375f6c23ef",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:34.159889Z",
     "start_time": "2024-04-02T07:39:34.146926Z"
    }
   },
   "source": [
    "df = df[['Risk_A', 'Risk_B', 'Risk_C', 'Risk_D', 'RiSk_E', 'Prob', 'Score', 'CONTROL_RISK', 'Audit_Risk', 'Risk', 'MONEY_Marks', 'Loss']]\n",
    "corr = df.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "64e56cee814993d3",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:34.199924Z",
     "start_time": "2024-04-02T07:39:34.190730Z"
    }
   },
   "source": [
    "df"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "2665b2c6640b9edf",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Data Clean Operation Is Done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93698df684ef540e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# I will Implement Knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f4f703ccf2472fd0",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:34.736541Z",
     "start_time": "2024-04-02T07:39:34.734356Z"
    }
   },
   "source": [
    "import math\n",
    "\n",
    "# Define a function to calculate the Euclidean distance between two points\n",
    "def euclidean_distance(x1, x2):\n",
    "    return math.sqrt(np.sum((x1 - x2) ** 2))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d154e3bb7d3ebb6e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:34.765921Z",
     "start_time": "2024-04-02T07:39:34.762997Z"
    }
   },
   "source": [
    "# Define the KNN function\n",
    "def knn_classification_with_euclidean_distance(X_train, y_train, X_test, k):\n",
    "    # List to store the predicted labels for the test set\n",
    "    y_pred = []\n",
    "    distances = []\n",
    "    \n",
    "    for i in range(len(X_test)):\n",
    "        for j in range(len(X_train)):\n",
    "            # Calculate the distance between the two points using euclidean_distance func where I defined above section\n",
    "            dist = euclidean_distance(X_test[i], X_train[j])\n",
    "            distances.append((dist, y_train[j]))\n",
    "\n",
    "        distances.sort()\n",
    "        neighbors = distances[:k] # Get the k nearest neighbors\n",
    "\n",
    "        counts = {} # Count the votes for each class\n",
    "        for neighbor in neighbors:\n",
    "            label = neighbor[1]\n",
    "            if label in counts:\n",
    "                counts[label] += 1\n",
    "            else:\n",
    "                counts[label] = 1\n",
    "\n",
    "        max_count = max(counts, key=counts.get) # Get the class with the most votes\n",
    "        y_pred.append(max_count)\n",
    "\n",
    "    return y_pred"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2dd97d72e3d65edf",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:34.812673Z",
     "start_time": "2024-04-02T07:39:34.810709Z"
    }
   },
   "source": [
    "# Define a function to calculate the Manhattan distance between two points\n",
    "def manhattan_distance(x1, x2):\n",
    "    return np.sum(np.abs(x1 - x2))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "eed31be7d7f63a06",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:34.858081Z",
     "start_time": "2024-04-02T07:39:34.855566Z"
    }
   },
   "source": [
    "def knn_regressor_with_manhattan_distance(X_train, y_train, X_test, k):\n",
    "    y_pred = []\n",
    "    distances = []\n",
    "    \n",
    "    for i in range(len(X_test)):\n",
    "        for j in range(len(X_train)):\n",
    "            # Calculate the distance between the two points using manhattan_distance func where I defined above section\n",
    "            dist = manhattan_distance(X_test[i], X_train[j])\n",
    "            distances.append((dist, y_train[j]))\n",
    "\n",
    "        distances.sort()\n",
    "        neighbors = distances[:k]# Get the k nearest neighbors\n",
    "        \n",
    "        mean_val = np.mean(neighbors)# Get the mean from the neighbors\n",
    "        y_pred.append(mean_val)\n",
    "\n",
    "    return y_pred"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**I finished preprocessing to data. I will go to implementing functions, start Part1** "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dcd13bdafe5ecbc7"
  },
  {
   "cell_type": "markdown",
   "id": "46e6e28eb596531e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# PART 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "34c465f71f36b4ba",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:34.930725Z",
     "start_time": "2024-04-02T07:39:34.927733Z"
    }
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class_df = df.drop(\"Audit_Risk\", axis=1)\n",
    "classification_X = class_df.drop([\"Risk\"], axis=1)\n",
    "classification_y = class_df[\"Risk\"]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**I am seperate my data for train %70 and test %30, so i will use train_test_split func in model_selection library**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f950fd060f677f2"
  },
  {
   "cell_type": "code",
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(classification_X, classification_y, test_size=0.3, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:34.958076Z",
     "start_time": "2024-04-02T07:39:34.955303Z"
    }
   },
   "id": "f22c84380429902e",
   "execution_count": 108,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "f799fb8b29030482",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**KNN Accuracy for k = 3 without k-fold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6ecf4b46a202e056",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:35.782803Z",
     "start_time": "2024-04-02T07:39:34.998649Z"
    }
   },
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert y_train and y_test to numpy arrays for using in knn_classification_with_euclidean_distance func\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "start_time = time.time() # i calculate prediction performance via using start_time and end_time \n",
    "y_pred = knn_classification_with_euclidean_distance(X_train_scaled, y_train, X_test_scaled, 3)\n",
    "end_time = time.time()\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Create a data frame to store k values and accuracies\n",
    "results_df = pd.DataFrame({'k': 3, 'Accuracy': accuracy}, index=[0])\n",
    "print(f\"k value: {3}, where accuracy is: {accuracy}\")\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "47fd25e822765b30",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Find Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5a7e60b05cc9b5a7",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:36.766972Z",
     "start_time": "2024-04-02T07:39:35.783596Z"
    }
   },
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = knn_classification_with_euclidean_distance(X_train_scaled, y_train, X_test_scaled, 3)\n",
    "confusion_matrix(y_test, y_pred)\n",
    "pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "8422814eb4440dea",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Find Confusion Matrix With K-fold Cross Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "26daa861707776c5",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:37.917575Z",
     "start_time": "2024-04-02T07:39:36.767723Z"
    }
   },
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "kf = KFold(n_splits=6, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store accuracy scores & confusion_matrices for each fold\n",
    "accuracy_scores = []\n",
    "confusion_matrices = []\n",
    "\n",
    "# Perform k-fold cross-validation via kf.split(X_train_scaled), this function give me an indexes subset of X_train_scaled actualy X_train\n",
    "for train_index, val_index in kf.split(X_train_scaled):\n",
    "    X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
    "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "\n",
    "    y_pred_fold = knn_classification_with_euclidean_distance(X_train_fold, y_train_fold, X_val_fold, 3)\n",
    "\n",
    "    # Calculate accuracy and confusion_matrix for current fold\n",
    "    accuracy = accuracy_score(y_val_fold, y_pred_fold)\n",
    "    cm = confusion_matrix(y_val_fold, y_pred_fold)\n",
    "\n",
    "    # Store accuracy score and confusion_matrix\n",
    "    accuracy_scores.append(accuracy)\n",
    "    confusion_matrices.append(cm)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "e4eeccdf6d29d4d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Classification Accuracy Performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3bf781dd4adae777",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:38.353081Z",
     "start_time": "2024-04-02T07:39:37.918426Z"
    }
   },
   "source": [
    "for i, score in enumerate(accuracy_scores):\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    sns.heatmap(confusion_matrices[i], annot=True, fmt='d', cmap='Greens')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True label')\n",
    "    i+=1\n",
    "    plt.xlabel(f'{i}. Fold cross validation Score: {score:.3f}')\n",
    "    plt.plot()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Calculate average accuracy across all folds\n",
    "avg_accuracy = np.mean(accuracy_scores)\n",
    "print(f\"Average accuracy: {avg_accuracy}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "188898ebea9e481d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Runtime Performance**\n",
    "As you can see to above plot graphics, we understood that last score is higher than others."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(f'Predict Runtime: {end_time - start_time:.6f} seconds')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:38.355620Z",
     "start_time": "2024-04-02T07:39:38.353671Z"
    }
   },
   "id": "8d46904dd7a55ecd",
   "execution_count": 113,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "83864c495304bfbf",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# PART 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "82dc85dd7291e0e5",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:38.381681Z",
     "start_time": "2024-04-02T07:39:38.356212Z"
    }
   },
   "source": [
    "bike = pd.DataFrame(pd.read_csv(\"datasets/day.csv\"))\n",
    "print(bike.head())\n",
    "print(bike.info())\n",
    "print(bike.describe())\n",
    "print(bike.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "3854053951ee8fbd",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Conclusion of Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dataset has 730 rows and 16 columns.\n",
    "Except one column, all others are either float or integer type.\n",
    "One column is date type.\n",
    "\n",
    "Looking at the data, it seems to be some fields that are categorical, but in integer/float type.\n",
    "We will analyse to convert them to categorical as integer."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b57c68452434910c"
  },
  {
   "cell_type": "code",
   "source": [
    "round(100 * (bike.isnull().sum() / len(bike)), 2).sort_values(ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:38.385367Z",
     "start_time": "2024-04-02T07:39:38.382240Z"
    }
   },
   "id": "72b201c81f94d20a",
   "execution_count": 115,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "668a63736d999c4b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:38.389109Z",
     "start_time": "2024-04-02T07:39:38.386031Z"
    }
   },
   "source": [
    "round((bike.isnull().sum(axis=1) / len(bike)) * 100, 2).sort_values(ascending=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "8f1b335fbbd0bd76",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Analysis**\n",
    "\n",
    "There are no missing / Null values either in columns or rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "dd56c3c584b2c4e8",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:38.392714Z",
     "start_time": "2024-04-02T07:39:38.389608Z"
    }
   },
   "source": [
    "bike_dup = bike.copy()\n",
    "bike_dup = bike_dup.drop_duplicates(keep='first')\n",
    "# we can assume same operation like this => bike_dup.drop_duplicates(subset=None, inplace=True)\n",
    "\n",
    "print(bike_dup.shape)\n",
    "print(bike.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "5ea91920bb53d5aa",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Analysis**\n",
    "The shape after running the drop duplicate command is same as the original dataframe.\n",
    "Hence we can conclude that there were zero duplicate values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "74610ab2aa09e46a",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:38.401570Z",
     "start_time": "2024-04-02T07:39:38.393872Z"
    }
   },
   "source": [
    "bike_dummy = bike.iloc[:, 1:16]\n",
    "\n",
    "for col in bike_dummy:\n",
    "    print(bike_dummy[col].value_counts(ascending=False), '\\n\\n\\n')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "fef2dbe3e7b76b1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**As you can see on above code output;**\n",
    "\n",
    "instant, dteday, casual and registered columns are nonessential, so we can remove these columns. Because;\n",
    "\n",
    "*instant* : its index,\n",
    "*dteday* : it has the date,\n",
    "*casual & registered* : i dont consider the columns that specify bike counts by customer categories since our objective is to determine the total bike count. Furthermore, we've introduced a new variable to represent the proportion of different customer types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "53dc785cfcb86890",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:38.404232Z",
     "start_time": "2024-04-02T07:39:38.402204Z"
    }
   },
   "source": [
    "bike_new = bike[\n",
    "    ['season', 'yr', 'mnth', 'holiday', 'weekday', 'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed', 'cnt']]\n",
    "# bike_new = bike[['temp', 'atemp', 'hum', 'windspeed', 'cnt']] we can see that columns are numerical"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c2d720ec66e9c8c2",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:38.411934Z",
     "start_time": "2024-04-02T07:39:38.404823Z"
    }
   },
   "source": [
    "bike_new.info()\n",
    "bike_new.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "f0775d8b24a3c761",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Creating Dummy Variables**\n",
    "I can drop all categorical data, so ['temp', 'atemp', 'hum', 'windspeed', 'cnt'] columns are usefull. But i can create dummy variable. \n",
    "Dummy variables are usefull because they allow us to include categorical variables in our analysis, which would otherwise be difficult to include due to their non-numeric nature. \n",
    "They can also help us to control for confounding factors and improve the validity of our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8deaebca0ab06029",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:38.415945Z",
     "start_time": "2024-04-02T07:39:38.412630Z"
    }
   },
   "source": [
    "bike_new['season'] = bike_new['season'].astype('category')\n",
    "bike_new['weathersit'] = bike_new['weathersit'].astype('category')\n",
    "bike_new['mnth'] = bike_new['mnth'].astype('category')\n",
    "bike_new['weekday'] = bike_new['weekday'].astype('category')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f9dee1661950f0c8",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:38.422064Z",
     "start_time": "2024-04-02T07:39:38.416518Z"
    }
   },
   "source": [
    "bike_new = pd.get_dummies(bike_new, drop_first=True)\n",
    "bike_new.info()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "da16c5eaa6ad11b0",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Go\n",
    "\n",
    "Splitting the data to Train and Test: - I am splitting the data into TRAIN and TEST (70:30 ratio), now,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "95c6c4ffbe39a298",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:38.425379Z",
     "start_time": "2024-04-02T07:39:38.422600Z"
    }
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "regression_df = bike_new\n",
    "regression_X = regression_df.drop([\"cnt\"], axis=1)\n",
    "regression_y = regression_df[\"cnt\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(regression_X, regression_y, test_size=0.3, random_state=42)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "2ab08ba2cb1a54ab",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Perform K-NN for k = 3 With K-fold Cross Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8724da9995a6b18b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:39.627376Z",
     "start_time": "2024-04-02T07:39:38.425865Z"
    }
   },
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert y_train and y_test to numpy arrays for using in knn_classification_with_euclidean_distance func\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "kf = KFold(n_splits=6, shuffle=True, random_state=42)\n",
    "\n",
    "r2_values = []\n",
    "mse_values = []\n",
    "rmse_values = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for train_index, val_index in kf.split(X_train_scaled):\n",
    "    X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
    "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "\n",
    "\n",
    "    start_time = time.time()\n",
    "    # Predict using KNN regression\n",
    "    y_pred_fold = knn_regressor_with_manhattan_distance(X_train_fold, y_train_fold, X_val_fold, 3)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # mean squared error, r2 score\n",
    "    # r2 = r2_score(y_val_fold, y_pred_fold)\n",
    "    mse = mean_squared_error(y_val_fold, y_pred_fold)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    # r2_values.append(r2)\n",
    "    mse_values.append(mse)\n",
    "    rmse_values.append(rmse)\n",
    "    \n",
    "# Calculate average mean\n",
    "# print(\"Average R2 Score:\", np.mean(r2_values))\n",
    "print(f\"Average Mean Squared Error: {np.mean(mse_values)}\")\n",
    "print(f\"Average Root Mean Squared error: {np.mean(rmse_values)}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "k_neighbors_predictions = knn.predict(X_test_scaled)\n",
    "accuracy_score(y_test, k_neighbors_predictions)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:39.657556Z",
     "start_time": "2024-04-02T07:39:39.628373Z"
    }
   },
   "id": "f046fb38a5b18d5e",
   "execution_count": 125,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "d2c47bf8d426108f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Runtime Performance**"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Mean Squared Error (MSE) is a metric commonly used to evaluate the performance of a regression model. It measures the average of the squares of the errors, \n",
    "which are the differences between actual values and predicted values. \n",
    "\n",
    "MSE quantifies the average squared difference between actual values and predicted values. A smaller MSE indicates better agreement between the predicted and actual values, \n",
    "whereas a larger MSE suggests poorer model performance."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c4fc6fb755c137f5"
  },
  {
   "cell_type": "code",
   "source": [
    "print(f'Predict Runtime: {end_time - start_time:.6f} seconds')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:39.668568Z",
     "start_time": "2024-04-02T07:39:39.658316Z"
    }
   },
   "id": "b8e80f602e3c511a",
   "execution_count": 126,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "f649ca8dd0bea952",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# PART 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "29b3339d8fd94a3e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:39.679557Z",
     "start_time": "2024-04-02T07:39:39.669389Z"
    }
   },
   "source": [
    "from sklearn import svm\n",
    "\n",
    "class_df = df.drop(\"Audit_Risk\", axis=1)\n",
    "classification_X = class_df.drop([\"Risk\"], axis=1)\n",
    "classification_y = class_df[\"Risk\"]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "bf34a6b03470515b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:39.682880Z",
     "start_time": "2024-04-02T07:39:39.680413Z"
    }
   },
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(classification_X, classification_y, test_size=0.3, random_state=42)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "d4653ffc17bd4c7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**KNN Accuracy for k = 3 without k-fold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "1ca137539790e526",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:39.700779Z",
     "start_time": "2024-04-02T07:39:39.683453Z"
    }
   },
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert y_train and y_test to numpy arrays\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "start_time = time.time()\n",
    "clf = svm.SVC(kernel='linear')  # Linear Kernel\n",
    "clf.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "y_pred = clf.predict(X_test)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "835a432f7da83a8c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:39.708714Z",
     "start_time": "2024-04-02T07:39:39.702527Z"
    }
   },
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(f\"Accuracy: {metrics.accuracy_score(y_test, y_pred)}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "7337314ebf8bd230",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Find Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "db14272a89d2b715",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:39.748999Z",
     "start_time": "2024-04-02T07:39:39.709718Z"
    }
   },
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)\n",
    "pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "84be92c2373a8154",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Find Confusion Matrix & And Roc Values For Each K-fold**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9af69e3cd188d07b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:39.803877Z",
     "start_time": "2024-04-02T07:39:39.751594Z"
    }
   },
   "source": [
    "import pylab as pl\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "kf = KFold(n_splits=6, shuffle=True, random_state=42)\n",
    "\n",
    "# List to store scores for each fold\n",
    "rocs = []\n",
    "roc_aucs = []\n",
    "confusion_matrices = []\n",
    "\n",
    "for train_index, val_index in kf.split(X_train_scaled):\n",
    "    X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
    "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "\n",
    "    clf = svm.SVC(kernel='linear')  # Linear Kernel\n",
    "    \n",
    "\n",
    "    clf.fit(X_train_fold, y_train_fold)\n",
    "    y_pred_fold = clf.predict(X_val_fold)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_val_fold, y_pred_fold)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    roc_aucs.append(roc_auc)\n",
    "\n",
    "    cm = confusion_matrix(y_val_fold, y_pred_fold)\n",
    "    confusion_matrices.append(cm)\n",
    "\n",
    "    ######### IMPORTANT INFO ###########\n",
    "    # The optimal cut-off would be where tpr is high and fpr is low\n",
    "    # tpr - (1-fpr) is zero or near to zero is the optimal cut off point\n",
    "    ####################################\n",
    "\n",
    "    i = np.arange(len(tpr))  # index for df\n",
    "    roc = pd.DataFrame(\n",
    "        {'fpr': pd.Series(fpr, index=i),\n",
    "         'tpr': pd.Series(tpr, index=i),\n",
    "         '1-fpr': pd.Series(1 - fpr, index=i),\n",
    "         'tf': pd.Series(tpr - (1 - fpr), index=i),\n",
    "         'thresholds': pd.Series(thresholds, index=i)\n",
    "         })\n",
    "\n",
    "    rocs.append(roc)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b3487d94934324e2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Show Optimum threshold & ROC Curves** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7b8135e22619555b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:40.892162Z",
     "start_time": "2024-04-02T07:39:39.806401Z"
    }
   },
   "source": [
    " for i, roc in enumerate(rocs):\n",
    "    # Plot tpr vs 1-fpr\n",
    "    fig, ax = pl.subplots()\n",
    "    pl.plot(roc['tpr'], color='black')\n",
    "    pl.plot(roc['1-fpr'], color='red')\n",
    "    pl.xlabel('False Positive Rate')\n",
    "    pl.ylabel('True Positive Rate')\n",
    "    pl.title(f\"Area under the {i + 1}. ROC curve : {roc_aucs[i]:.3f}\")\n",
    "    pl.legend([\"tpr\", \"1-fpr\"], loc=\"lower right\")\n",
    "\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    sns.heatmap(confusion_matrices[i], annot=True)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('False Label')\n",
    "    plt.plot()\n",
    "\n",
    "    roc_optimum_threshold = roc.iloc[(roc.tf - 0).abs().argsort()[:1]]\n",
    "    print(f\"{i + 1}. ROC Optimum threshold= {list(roc_optimum_threshold['thresholds'])}\")\n",
    "\n",
    "    plt.show()\n",
    "    ax.set_xticklabels([])"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "77edc718a6472c1b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Runtime Performance**"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Area Under Curve (AUC) is closer to 1 are more good, robust etc model than others. So as you can see, i get the 1 which optimal thresold 1 to."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c1fe5015153a7113"
  },
  {
   "cell_type": "code",
   "source": [
    "print(f'Predict Runtime: {end_time - start_time:.6f} seconds')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:40.894509Z",
     "start_time": "2024-04-02T07:39:40.892768Z"
    }
   },
   "id": "8a3c4cde38d45ecc",
   "execution_count": 134,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4423ac5290d754c3"
  },
  {
   "cell_type": "markdown",
   "id": "fce8d048ab3b7655",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# PART 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af03520187ee2f7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Get Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a0cc052c105a15b3",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:40.898111Z",
     "start_time": "2024-04-02T07:39:40.895019Z"
    }
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "regression_df = bike_new\n",
    "regression_X = regression_df.drop([\"cnt\"], axis=1)\n",
    "regression_y = regression_df[\"cnt\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(regression_X, regression_y, test_size=0.3, random_state=42)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "fa6c47572fe25b34",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Regressor based on the linear SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "de0c7a18a60309d3",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:40.919625Z",
     "start_time": "2024-04-02T07:39:40.899779Z"
    }
   },
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "svr = SVR(kernel='linear', C=6)\n",
    "start_time = time.time()\n",
    "svr.fit(X_train, y_train)\n",
    "y_pred = svr.predict(X_test)\n",
    "end_time = time.time()\n",
    "\n",
    "#r2 score, mean squared error & rmse\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f'Single R2 Score (Before k-fold cross validation): {r2:.3f}')\n",
    "print(f'Mean Squared Error: {mse:.3f}')\n",
    "print(f'Root Mean Squared error: {rmse:.3f}')\n",
    "print(f'Test Score: {svr.score(X_test, y_test):.3f}')\n",
    "print(f'Train Score: {svr.score(X_train, y_train):.3f}')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d8d0730e8bab2ab7",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:40.958608Z",
     "start_time": "2024-04-02T07:39:40.920122Z"
    }
   },
   "source": [
    "# Convert y_train and y_test to numpy arrays\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Initialize the Linear SVR model\n",
    "svr = SVR(kernel='linear', C=6)\n",
    "kf = KFold(n_splits=6, shuffle=True, random_state=42)\n",
    "\n",
    "r2_values = []\n",
    "mse_values = []\n",
    "rmse_values = []\n",
    "\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "\n",
    "    # Predict using LSVM regression\n",
    "    svr.fit(X_train_fold, y_train_fold)\n",
    "    y_pred_fold = svr.predict(X_val_fold)\n",
    "\n",
    "    # mean squared error, r2 score\n",
    "    r2 = r2_score(y_val_fold, y_pred_fold)\n",
    "    mse = mean_squared_error(y_val_fold, y_pred_fold)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    r2_values.append(r2)\n",
    "    mse_values.append(mse)\n",
    "    rmse_values.append(rmse)\n",
    "\n",
    "# Mean squared error and R2 scores\n",
    "mse_mean = np.mean(mse_values)\n",
    "r2_mean = np.mean(r2_values)\n",
    "\n",
    "print(f'Mean Squared Error: {mse_mean:.3f}')\n",
    "print(f'R2 Score Mean After 6-fold cross validation: {r2_mean:.3f}')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Final Test"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b661f808afb476c"
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "229c5f3fb516b389",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:40.962677Z",
     "start_time": "2024-04-02T07:39:40.959181Z"
    }
   },
   "source": [
    "y_pred = svr.predict(X_test)\n",
    "print(f\"Final R2 Score After k-fold cross validation with test data:  {r2_score(y_test, y_pred):.3f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Runtime Performance**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62611c739ed2d5d3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Firstly, I find mse which after k-fold cross validation is better than before one.  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91d958fa4ef2f18e"
  },
  {
   "cell_type": "code",
   "source": [
    "print(f'Predict Runtime: {end_time - start_time:.6f} seconds')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:40.964817Z",
     "start_time": "2024-04-02T07:39:40.963162Z"
    }
   },
   "id": "79c150d6f5398d2c",
   "execution_count": 139,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PART 5"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95d6ddf83f4a3905"
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn import svm\n",
    "\n",
    "class_df = df.drop(\"Audit_Risk\", axis=1)\n",
    "classification_X = class_df.drop([\"Risk\"], axis=1)\n",
    "classification_y = class_df[\"Risk\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(classification_X, classification_y, test_size=0.3, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert y_train and y_test to numpy arrays\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "clf = svm.SVC(kernel='rbf')  # Rbf Kernel\n",
    "start_time = time.time()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "end_time = time.time()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:40.976037Z",
     "start_time": "2024-04-02T07:39:40.965278Z"
    }
   },
   "id": "b8e9765549976d92",
   "execution_count": 140,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:40.978698Z",
     "start_time": "2024-04-02T07:39:40.976613Z"
    }
   },
   "id": "26e936da30596cf8",
   "execution_count": 141,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Find Confusion Matrix**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dbd78af19e610a3f"
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred)\n",
    "pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:40.992673Z",
     "start_time": "2024-04-02T07:39:40.979519Z"
    }
   },
   "id": "1399c16de4b5469a",
   "execution_count": 142,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Find Confusion Matrix & And Roc Values For Each K-fold**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec1937909d4b2234"
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pylab as pl\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "kf = KFold(n_splits=6, shuffle=True, random_state=42)\n",
    "\n",
    "# List to store scores for each fold\n",
    "rocs = []\n",
    "roc_aucs = []\n",
    "confusion_matrices = []\n",
    "\n",
    "for train_index, val_index in kf.split(X_train_scaled):\n",
    "    X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n",
    "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "\n",
    "    clf = svm.SVC(kernel='rbf')  # Linear Kernel\n",
    "    clf.fit(X_train_fold, y_train_fold)\n",
    "    y_pred_fold = clf.predict(X_val_fold)\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_val_fold, y_pred_fold)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    roc_aucs.append(roc_auc)\n",
    "\n",
    "    cm = confusion_matrix(y_val_fold, y_pred_fold)\n",
    "    confusion_matrices.append(cm)\n",
    "\n",
    "    ######### IMPORTANT INFO ###########\n",
    "    # The optimal cut-off would be where tpr is high and fpr is low\n",
    "    # tpr - (1-fpr) is zero or near to zero is the optimal cut off point\n",
    "    ####################################\n",
    "\n",
    "    i = np.arange(len(tpr))  # index for df\n",
    "    roc = pd.DataFrame(\n",
    "        {'fpr': pd.Series(fpr, index=i),\n",
    "         'tpr': pd.Series(tpr, index=i),\n",
    "         '1-fpr': pd.Series(1 - fpr, index=i),\n",
    "         'tf': pd.Series(tpr - (1 - fpr), index=i),\n",
    "         'thresholds': pd.Series(thresholds, index=i)\n",
    "         })\n",
    "\n",
    "    rocs.append(roc)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:41.011868Z",
     "start_time": "2024-04-02T07:39:40.993251Z"
    }
   },
   "id": "a009a5f647b1ed37",
   "execution_count": 143,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Show Optimum threshold & ROC Curves** "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f774fa4faf9af799"
  },
  {
   "cell_type": "code",
   "source": [
    " for i, roc in enumerate(rocs):\n",
    "    # Plot tpr vs 1-fpr\n",
    "    fig, ax = pl.subplots()\n",
    "    pl.plot(roc['tpr'], color='black')\n",
    "    pl.plot(roc['1-fpr'], color='red')\n",
    "    pl.xlabel('1-False Positive Rate')\n",
    "    pl.ylabel('True Positive Rate')\n",
    "    pl.title(f\"Area under the {i + 1}. ROC curve : {roc_aucs[i]}\")\n",
    "    pl.legend([\"tpr\", \"1-fpr\"], loc=\"lower right\")\n",
    "\n",
    "    plt.figure(figsize=(3, 3))\n",
    "    sns.heatmap(confusion_matrices[i], annot=True)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('False Label')\n",
    "    plt.plot()\n",
    "    ax.set_xticklabels([])\n",
    "\n",
    "    roc_optimum_threshold = roc.iloc[(roc.tf - 0).abs().argsort()[:1]]\n",
    "    print(f\"{i + 1}-fold ROC Optimum threshold= {list(roc_optimum_threshold['thresholds'])}\")\n",
    "\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:42.106821Z",
     "start_time": "2024-04-02T07:39:41.012520Z"
    }
   },
   "id": "3340e24a664c4f13",
   "execution_count": 144,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Runtime Performance**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "963335b61f6ddedc"
  },
  {
   "cell_type": "code",
   "source": [
    "print(f'Predict Runtime: {end_time - start_time:.6f} seconds')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:42.109876Z",
     "start_time": "2024-04-02T07:39:42.107575Z"
    }
   },
   "id": "9063180fb87e6fd6",
   "execution_count": 145,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PART 6"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f151981c75884ead"
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "class_df = df.drop(\"Audit_Risk\", axis=1)\n",
    "classification_X = class_df.drop([\"Risk\"], axis=1)\n",
    "classification_y = class_df[\"Risk\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(classification_X, classification_y, test_size=0.3, random_state=42)\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=1)\n",
    "start_time = time.time()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "end_time = time.time()\n",
    "\n",
    "accuracy = dt.score(X_test, y_test)  # we can also find accuracy: print(accuracy_score(y_test, y_pred))\n",
    "print(f'Test set accuracy: {accuracy:.3f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:42.122779Z",
     "start_time": "2024-04-02T07:39:42.110419Z"
    }
   },
   "id": "b77a0f8428c85d8",
   "execution_count": 146,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Pruning Strategies**\n",
    "\n",
    "I am try to use min_impurity_decrease and max_depth parameters. \n",
    "The **min_impurity_decrease** parameter controls for how much the impurity of a node must be reduced by splitting it, and the **max_depth** parameter controls the maximum depth of the tree. \n",
    "By setting these parameters, appropriately, i can prune the tree to prevent it from overfitting the data."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1aec5d38b5d31468"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Different 2 Pruning Strategies**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "140b94ab6bc15702"
  },
  {
   "cell_type": "code",
   "source": [
    "# first second pruning strategies using min_impurity_decrease\n",
    "dt_min_impurity = DecisionTreeClassifier(min_impurity_decrease=0.01, random_state=1)\n",
    "dt_min_impurity.fit(X_train, y_train)\n",
    "\n",
    "# second pruning strategies using max_depth\n",
    "dt_max_depth = DecisionTreeClassifier(max_depth=5, random_state=1)\n",
    "dt_max_depth.fit(X_train, y_train)\n",
    "\n",
    "print(f'Test set accuracy (min_impurity_decrease): {dt_min_impurity.score(X_test, y_test):.3f}')\n",
    "print(f'Test set accuracy (max_depth): {dt_max_depth.score(X_test, y_test):.3f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:42.129140Z",
     "start_time": "2024-04-02T07:39:42.123354Z"
    }
   },
   "id": "6a700a5d514e5831",
   "execution_count": 147,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Apply K-Fold Cross Validation**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f91192a88a3a719"
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=6, shuffle=True, random_state=42)\n",
    "accuracy_scores = []\n",
    "fold_number = 1\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(classification_X, classification_y, test_size=0.3, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "\n",
    "    dt = DecisionTreeClassifier(random_state=1)\n",
    "    dt.fit(X_train_fold, y_train_fold)\n",
    "    accuracy = dt.score(X_val_fold, y_val_fold)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    \n",
    "    print(f\"{fold_number}. Fold Cross Validation accuracy: {accuracy}\")\n",
    "    fold_number +=1\n",
    "\n",
    "print(f\"\\nK-Fold Cross Validation accuracy mean: {np.mean(accuracy_scores)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:42.140814Z",
     "start_time": "2024-04-02T07:39:42.129771Z"
    }
   },
   "id": "39f489509cfa9469",
   "execution_count": 148,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.tree import _tree\n",
    "\n",
    "def tree_to_set_of_rules(tree, features):\n",
    "    tree_ = tree.tree_\n",
    "    feature_name = [\n",
    "        features[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "        for i in tree_.feature\n",
    "    ]\n",
    "    print(\"def predict({}):\".format(\", \".join(features)))\n",
    "\n",
    "    def recurse(node, depth):\n",
    "        indent = \"    \" * depth\n",
    "        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "            name = feature_name[node]\n",
    "            threshold = tree_.threshold[node]\n",
    "            print(\"{}if {} <= {}:\".format(indent, name, np.round(threshold, 2)))\n",
    "            recurse(tree_.children_left[node], depth + 1)\n",
    "            print(\"{}else:  # if {} > {}\".format(indent, name, np.round(threshold, 2)))\n",
    "            recurse(tree_.children_right[node], depth + 1)\n",
    "        else:\n",
    "            # print(\"{}return {} {} {}\".format(indent, tree_.value[node], \"samples\", tree_.n_node_samples[node])) #> if you wanna see classification\n",
    "            print(\"{}return {} {}\".format(indent, tree_.n_node_samples[node], \"samples\"))  # I will use this, because a bit simple and clean\n",
    "\n",
    "    recurse(0, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:42.144238Z",
     "start_time": "2024-04-02T07:39:42.141387Z"
    }
   },
   "id": "d793bfe70764a89c",
   "execution_count": 149,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(classification_X, classification_y, test_size=0.3, random_state=42)\n",
    "model = dt.fit(X_train, y_train)\n",
    "tree_to_set_of_rules(dt, X_train.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:42.148877Z",
     "start_time": "2024-04-02T07:39:42.144733Z"
    }
   },
   "id": "60bea508deda2cbd",
   "execution_count": 150,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# to compare my output and library function's output,\n",
    "from sklearn import tree\n",
    "text_representation = tree.export_text(dt)\n",
    "print(text_representation)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:42.151456Z",
     "start_time": "2024-04-02T07:39:42.149405Z"
    }
   },
   "id": "8eb48bf8d42c5cf4",
   "execution_count": 151,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Report**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de1a786c6e4644f2"
  },
  {
   "cell_type": "code",
   "source": [
    "print(f'Predict Runtime: {end_time - start_time:.6f} seconds')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:42.153401Z",
     "start_time": "2024-04-02T07:39:42.151904Z"
    }
   },
   "id": "20128edb1bc6261e",
   "execution_count": 152,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PART 7"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c03ee158cb2033ee"
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "regression_df = bike_new\n",
    "regression_X = regression_df.drop([\"cnt\"], axis=1)\n",
    "regression_y = regression_df[\"cnt\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(regression_X, regression_y, test_size=0.3, random_state=42)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Detect single runtime performance\n",
    "dt = DecisionTreeRegressor(random_state=1, max_depth=5, min_impurity_decrease=0.1)\n",
    "start_time = time.time()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "end_time = time.time()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:42.161291Z",
     "start_time": "2024-04-02T07:39:42.153890Z"
    }
   },
   "id": "4bb01f7927dc81be",
   "execution_count": 153,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Apply K-Fold Cross Validation**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "420b9d5c08afd4bf"
  },
  {
   "cell_type": "code",
   "source": [
    "fold_number = 1\n",
    "accuracy_scores = []\n",
    "kf = KFold(n_splits=6, shuffle=True, random_state=42)\n",
    "\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "    \n",
    "    dt = DecisionTreeRegressor(random_state=1, max_depth=5, min_impurity_decrease=0.1)\n",
    "    dt.fit(X_train_fold, y_train_fold)\n",
    "    y_pred = dt.predict(X_val_fold)\n",
    "    \n",
    "    accuracy = dt.score(X_val_fold, y_val_fold)  # we can also find accuracy: print(accuracy_score(y_test, y_pred))\n",
    "    print(f\"{fold_number}. Fold Cross Validation accuracy: {accuracy}\")\n",
    "    fold_number +=1\n",
    "\n",
    "print(\"\\n\")\n",
    "tree_to_set_of_rules(dt, regression_X.columns) # we can use again same tree_to_code function"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:42.172780Z",
     "start_time": "2024-04-02T07:39:42.161811Z"
    }
   },
   "id": "443a0c0c0e4b5afc",
   "execution_count": 154,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Final Test**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8648f76b87cbebc7"
  },
  {
   "cell_type": "code",
   "source": [
    "y_pred = dt.predict(X_test)\n",
    "print(f\"Final R2 Score After k-fold cross validation with test data:  {r2_score(y_test, y_pred):.3f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:42.175296Z",
     "start_time": "2024-04-02T07:39:42.173302Z"
    }
   },
   "id": "9af3c7fa087fe552",
   "execution_count": 155,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Performance**\n",
    "As you see in the above outputs, K-cross validation's predict value is a bit higher than final predeict value.  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60fe0825254cb98"
  },
  {
   "cell_type": "code",
   "source": [
    "print(f'Predict Runtime: {end_time - start_time:.6f} seconds')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:39:42.177449Z",
     "start_time": "2024-04-02T07:39:42.175873Z"
    }
   },
   "id": "c2ea2b772320eb9b",
   "execution_count": 156,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
